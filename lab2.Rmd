---
title: "lab2"
output: html_document
date: "2026-02-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lab 2 - Aprendizaje no supervisado

## Clustering

### Preprocesamiento 
s
```{r, echo=FALSE}
# Librerías necesarias
library(tidyverse)
library(cluster)
library(factoextra)
library(clustertend)
library(NbClust)
library(GGally)
library(dendextend)

# Cargar dataset
movies <- read.csv("movies_2026.csv")

# Revisar estructura
str(movies)
summary(movies)

```

#### Selección de variables

Eliminamos variables que no aportan a la formación de grupos:

id, originalTitle, title, homePage, actorsCharacter, releaseDate, director, productionCompany, actors


Variables textuales no numéricas

Trabajaremos con variables numéricas relevantes para comportamiento y desempeño:
```{r, echo=FALSE}
movies_clean <- movies %>%
  select(popularity, budget, revenue, runtime,
         genresAmount, productionCoAmount,
         productionCountriesAmount, voteCount,
         voteAvg, actorsPopularity,
         actorsAmount, castWomenAmount,
         castMenAmount, releaseYear) %>%
  mutate(across(everything(), ~ as.numeric(as.character(.)))) %>%
  drop_na()

movies_scaled <- scale(movies_clean)

```

### Tendencia al Agrupamiento
#### Estadistico de Hopkins
```{r}
set.seed(123)
hopkins_stat <- hopkins(movies_scaled, n = nrow(movies_scaled)-1)
hopkins_stat

```

#### VAT
```{r}
fviz_dist(dist(movies_scaled))

```

### Numero Optimo de Clusters
#### Metodo del Codo
```{r}
fviz_nbclust(movies_scaled, kmeans, method = "wss") +
  ggtitle("Método del Codo")

```

#### Metodo de silueta
```{r}
fviz_nbclust(movies_scaled, kmeans, method = "silhouette") +
  ggtitle("Método de Silueta")

```

## 1.4 Aplicación de K-medias y Clustering Jerárquico

### K-medias

```{r}
set.seed(123)

k_opt <- 3  # Ajustar según los métodos del codo y silueta

kmeans_model <- kmeans(movies_scaled, centers = k_opt, nstart = 25)

# Agregar cluster al dataset
movies_clean$cluster_kmeans <- as.factor(kmeans_model$cluster)

# Visualización
fviz_cluster(kmeans_model, data = movies_scaled,
             ellipse.type = "convex",
             ggtheme = theme_minimal(),
             main = "Clusters con K-means")


# Matriz de distancias
dist_matrix <- dist(movies_scaled)

# Método de Ward
hc_model <- hclust(dist_matrix, method = "ward.D2")

# Dendrograma
plot(hc_model, labels = FALSE, main = "Dendrograma - Clustering Jerárquico")

# Cortar el árbol en k clusters
hc_clusters <- cutree(hc_model, k = k_opt)

movies_clean$cluster_hc <- as.factor(hc_clusters)

# Visualización
fviz_cluster(list(data = movies_scaled, cluster = hc_clusters),
             ellipse.type = "convex",
             ggtheme = theme_minimal(),
             main = "Clusters Jerárquicos")

table(Kmeans = movies_clean$cluster_kmeans,
      Jerarquico = movies_clean$cluster_hc)



sil_kmeans <- silhouette(kmeans_model$cluster, dist_matrix)
fviz_silhouette(sil_kmeans)
mean(sil_kmeans[,3])

sil_hc <- silhouette(hc_clusters, dist_matrix)
fviz_silhouette(sil_hc)
mean(sil_hc[,3])


movies_clean %>%
  group_by(cluster_kmeans) %>%
  summarise(across(where(is.numeric),
                   list(media = mean,
                        mediana = median),
                   na.rm = TRUE))


table(movies_clean$cluster_kmeans)

```

## Analisis de Componentes Principales PCA

### ¿Se pueden incluir variables categoricas?

Las variables categóricas como:

-originalLanguage

-genres

-productionCountry

-director

-productionCompany

No pueden incluirse directamente en PCA porque:

-PCA trabaja con matriz de covarianza/correlación

-Requiere variables numéricas continuas

-Transformarlas con One-Hot Encoding generaría cientos de variables

-Alta cardinalidad → distorsiona la varianza

### ¿Es conveniente aplicar PCA?

Trabajando solo con variables numericas:

```{r, echo=FALSE}
library(tidyverse)
library(psych)
library(corrplot)

movies_pca <- movies %>%
  select(popularity, budget, revenue, runtime,
         genresAmount, productionCoAmount,
         productionCountriesAmount, voteCount,
         voteAvg, actorsPopularity,
         actorsAmount, castWomenAmount,
         castMenAmount) %>%
  mutate(across(everything(), as.numeric)) %>%
  drop_na()

movies_scaled <- scale(movies_pca)

cor_matrix <- cor(movies_scaled)
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.7)


KMO(cor_matrix)

cortest.bartlett(cor_matrix, n = nrow(movies_scaled))
```

La matriz de correlación evidencia dependencias lineales moderadas y fuertes entre varias variables, lo que justifica la aplicación de PCA para reducir dimensionalidad. El índice KMO global de 0.66 indica que la estructura de correlaciones es aceptable para aplicar análisis factorial o PCA. El test de esfericidad de Bartlett resultó altamente significativo (p < 0.001), lo que confirma que la matriz de correlación no es identidad y que existen correlaciones suficientes para aplicar PCA. Se seleccionaron los primeros 4 componentes principales, ya que presentan valores propios mayores a 1 y explican aproximadamente el 55% de la variabilidad total.

### Aplicacion del PCA

```{r, echo=FALSE}
pca_model <- prcomp(movies_scaled, center = TRUE, scale. = TRUE)
summary(pca_model)

library(factoextra)

fviz_eig(pca_model, addlabels = TRUE)

pca_model$rotation

fviz_pca_var(pca_model, col.var = "contrib")

fviz_pca_biplot(pca_model,
                repel = TRUE,
                col.var = "blue",
                col.ind = "gray")
```

El análisis de componentes principales permitió identificar cuatro dimensiones fundamentales en el desempeño de las películas: impacto comercial, estructura del elenco, complejidad productiva e inversión económica.

Esta reducción facilita la construcción futura de modelos predictivos, disminuye problemas de colinealidad y permite segmentar películas en función de características estructurales más compactas.

